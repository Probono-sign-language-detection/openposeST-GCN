# openposeST-GCN
Inference Gloss from Sign Language  Video with OpenPose and ST-GCN!  
OpenPoseì™€ WLASL Preatrained ST-GCNì„ ì´ìš©í•œ ìˆ˜í™” ë²ˆì—­ 
  
## ğŸš€ Import pyopenpose
If you want use pyopenpose, see [here](https://cmu-perceptual-computing-lab.github.io/openpose/web/html/doc/md_doc_03_python_api.html)  
í•œêµ­ì–´ ê°€ì´ë“œë¥¼ ì›í•˜ì‹ ë‹¤ë©´, ì œ [ë¸”ë¡œê·¸](https://blog.naver.com/paragonyun/223160841596)ë¥¼ ë°©ë¬¸í•˜ì…”ì„œ ë”°ë¼í•˜ì…”ë„ ë©ë‹ˆë‹¤.
  
## ğŸ‘€ How to Use
0. You have to be ready with `pyopenpose` 
1. Clone my repo
```
git clone https://github.com/Probono-sign-language-detection/openposeST-GCN.git
```
2. install what you need
```
pip install -r requirements.txt
```
3. main.py
```
python stgcn_test.py
```

## ğŸ¤– Results
![image](https://github.com/Probono-sign-language-detection/openposeST-GCN/assets/83996346/de1fab2d-783c-4f8e-ae64-0055eb8f3e98)  
You can get label index for your video's frames! But actually it is too slow for CPU Environment.   
So If you want to get a label in real-time task, I recommend to use the setting(import pyopenpose step!) for CUDA Environment.  
